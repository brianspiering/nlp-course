{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Bayes Rule to mutli-class document classfication <br> (from scratch)\n",
    "-----\n",
    "\n",
    "![](images/bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always Add  Smoothing to Naive Bayes\n",
    "------\n",
    "\n",
    "![](images/laplace.png)\n",
    "Laplace Smoothing in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Naive Bayes Classification Steps\n",
    "-------\n",
    "\n",
    "1. Get labeled data\n",
    "1. Preprocess\n",
    "1. Apply Mulitnomial Naive Bayes\n",
    "    1. Calculate document class priors\n",
    "    1. Calculate conditional probabilities of each word for each class\n",
    "    1. Calculate the proportional probabilities for each class of new document\n",
    "    1. Pick the winning class\n",
    "1. Evaluate with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    from dataclasses import dataclass\n",
    "except ModuleNotFoundError:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'dataclasses'])\n",
    "    from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Data:\n",
    "    id_num: int\n",
    "    label: str\n",
    "    tokens: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [Data(id_num=42, label='cat', tokens=\"ğŸ¯ ğŸ˜º ğŸ© ğŸ˜º\".split()),\n",
    "         Data(43, 'dog',  \"ğŸ¶ ğŸ¶ ğŸˆ ğŸ© ğŸˆ ğŸ¶ ğŸ¶\".split()),\n",
    "         Data(44, 'fish', \"ğŸŸ ğŸ  ğŸ \".split()),\n",
    "         Data(45, 'cat',  \"ğŸ¶ ğŸˆ ğŸˆ ğŸˆ\".split()),\n",
    "         Data(46, 'fish', \"ğŸŸ ğŸ¬ ğŸ¬ ğŸ  ğŸ \".split()),\n",
    "         Data(47, 'fish', \"ğŸ¡ ğŸ¡ ğŸ  ğŸ¶\".split()),\n",
    "         Data(48, 'dog',  \"ğŸ¶ ğŸ¶ ğŸˆ ğŸ© ğŸ¶ ğŸ¶\".split()),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate document class priors\n",
    "---- \n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'fish'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "labels = {d.label for d in train}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(train)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fish': 0.42857142857142855,\n",
       " 'dog': 0.2857142857142857,\n",
       " 'cat': 0.2857142857142857}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_priors = {label:sum(1 for d in train if d.label == label)/n_docs\n",
    "                 for label in labels}\n",
    "doc_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities of each word for each class\n",
    "-----\n",
    "\n",
    "$$P(w|c) = \\frac{count(w,c)+1}{count(c)+|V|}$$\n",
    "\n",
    "with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = chain.from_iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: {'ğŸ˜º', 'ğŸ©', 'ğŸ¡', 'ğŸŸ', 'ğŸˆ', 'ğŸ¬', 'ğŸ¶', 'ğŸ¯', 'ğŸ '}\n",
      "Cardinality of vocab: 9\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "vocab = set(flatten(d.tokens for d in train))\n",
    "print(\"Vocab:\", vocab)\n",
    "\n",
    "# Cardinality of vocabulary\n",
    "v = len(vocab)\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'fish': defaultdict(float,\n",
       "                         {'ğŸ˜º': 0.047619047619047616,\n",
       "                          'ğŸ©': 0.047619047619047616,\n",
       "                          'ğŸ¡': 0.14285714285714285,\n",
       "                          'ğŸŸ': 0.14285714285714285,\n",
       "                          'ğŸˆ': 0.047619047619047616,\n",
       "                          'ğŸ¬': 0.14285714285714285,\n",
       "                          'ğŸ¶': 0.09523809523809523,\n",
       "                          'ğŸ¯': 0.047619047619047616,\n",
       "                          'ğŸ ': 0.2857142857142857}),\n",
       "             'dog': defaultdict(float,\n",
       "                         {'ğŸ˜º': 0.045454545454545456,\n",
       "                          'ğŸ©': 0.13636363636363635,\n",
       "                          'ğŸ¡': 0.045454545454545456,\n",
       "                          'ğŸŸ': 0.045454545454545456,\n",
       "                          'ğŸˆ': 0.18181818181818182,\n",
       "                          'ğŸ¬': 0.045454545454545456,\n",
       "                          'ğŸ¶': 0.4090909090909091,\n",
       "                          'ğŸ¯': 0.045454545454545456,\n",
       "                          'ğŸ ': 0.045454545454545456}),\n",
       "             'cat': defaultdict(float,\n",
       "                         {'ğŸ˜º': 0.17647058823529413,\n",
       "                          'ğŸ©': 0.11764705882352941,\n",
       "                          'ğŸ¡': 0.058823529411764705,\n",
       "                          'ğŸŸ': 0.058823529411764705,\n",
       "                          'ğŸˆ': 0.23529411764705882,\n",
       "                          'ğŸ¬': 0.058823529411764705,\n",
       "                          'ğŸ¶': 0.11764705882352941,\n",
       "                          'ğŸ¯': 0.11764705882352941,\n",
       "                          'ğŸ ': 0.058823529411764705})})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_prob = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in labels:\n",
    "    # For a given label, get a list of all the tokens for all the docs \n",
    "    label_tokens = list(chain.from_iterable(d.tokens for d in train if d.label == label))\n",
    "    for token in vocab:\n",
    "        # Find conditional probability: token count / total count\n",
    "        cond_prob[label][token] = (label_tokens.count(token)+1) / (len(label_tokens) + v)\n",
    "cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that each label is a pmf\n",
    "for label in labels:\n",
    "    assert round(sum(cond_prob[label].values())) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new document without a label,  calculate the proportional probabilities for each class\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c | X) = P(c) â€¢  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def  product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fish', 0.0)\n",
      "('dog', 0.0)\n",
      "('cat', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# test = Data(id_num=90, label=None, tokens=\"ğŸ˜º\".split())\n",
    "# test = Data(id_num=91, label=None, tokens=\"ğŸ¶ ğŸ¶\".split()) \n",
    "# test = Data(id_num=92, label=None, tokens=\"ğŸ¶ ğŸ˜º\".split())\n",
    "# test = Data(id_num=93, label=None, tokens=\"ğŸˆ ğŸˆ ğŸ¶ ğŸ¶ ğŸ¡ ğŸ¬ ğŸ¡ ğŸ¬ ğŸ¡ ğŸ¬\".split())\n",
    "# test = Data(id_num=94, label=None, tokens=\"ğŸ¬\".split())\n",
    "test = Data(id_num=95, label=None, tokens=\"ğŸ¹\".split()) # Out of sample prediction\n",
    "# test = Data(id_num=95, label=None, tokens=\"ğŸ¹ ğŸ¶\".split()) # Out of sample prediction\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in test.tokens)\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the winning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish dog cat\n"
     ]
    }
   ],
   "source": [
    "# Handle ties\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(*(k for k, v in prob_predicted.items() if v == prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Naive Bayes is simple and powerful algorithm for text classification\n",
    "- Always add smoothing to Naive Bayes\n",
    "- Use the Standard Library to create elegant and performant code\n",
    "- Dataclasses are coming soon; Get ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Resources\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bayes_slide.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The data from the slide\n",
    "# train = [Data(id_num=1, label='c', tokens=\"C B C\".split()),\n",
    "#          Data(2, 'c', \"C C S\".split()),\n",
    "#          Data(3, 'c', \"C M\".split()),\n",
    "#          Data(4, 'j', \"T J C\".split()),\n",
    "#         ]\n",
    "\n",
    "# test = Data(5, label=None, tokens=\"C C C T J\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Zoo\n",
    "------\n",
    "\n",
    "ğŸ¶\n",
    "ğŸ•\n",
    "ğŸ©\n",
    "ğŸ¯\n",
    "ğŸˆ\n",
    "ğŸ˜º\n",
    "ğŸŸ\n",
    "ğŸ \n",
    "ğŸ¡\n",
    "ğŸ¬\n",
    "ğŸ¹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
