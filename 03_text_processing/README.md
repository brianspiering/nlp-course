Segmenting, Tokenizing, & Stemming
----

__Required__:

- Complete `workbook` in folder
- [Word Tokenization](https://www.youtube.com/watch?v=jBk24DI8kg0&index=4&list=PLhVhwi0Pz282aSA2uZX4jR3SkF3BKyMOK)
- [Word Normalization and Stemming](https://www.youtube.com/watch?v=2s7f8mBwnko&list=PLhVhwi0Pz282aSA2uZX4jR3SkF3BKyMOK&index=5)
- [Sentence Segmentation](https://www.youtube.com/watch?v=di0N3kXfGYg&list=PLhVhwi0Pz282aSA2uZX4jR3SkF3BKyMOK&index=6)
- Read: [Read Part I & II](http://textminingonline.com/dive-into-nltk-part-ii-sentence-tokenize-and-word-tokenize)

__Optional__:

+ [Another video about tokenizing](https://www.coursera.org/learn/natural-language-processing/lecture/Bx5nh/02-07-preprocessing-11-30)
+ [Another video about stemming](https://www.coursera.org/learn/natural-language-processing/lecture/byUdd/02-04-morphological-similarity-stemming-14-54)
+ [Webinar on Tokenizing Words and Sentences with NLTK](https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/)

        
    